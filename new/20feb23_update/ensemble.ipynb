{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 12652538658899580371,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5748293632\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 912110427178217356\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "  \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import shutil\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"Num GPUs Available: \", physical_devices, len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.test.gpu_device_name()\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model.....\n",
      "Model: \"ensemble\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Functional)              (None, 2)            15242050    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inceptionv3 (Functional)        (None, 2)            23903010    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 2)            0           vgg16[0][0]                      \n",
      "                                                                 inceptionv3[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 39,145,060\n",
      "Trainable params: 2,627,588\n",
      "Non-trainable params: 36,517,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "initial_lr = 1e-3 # learning rate\n",
    "epochs = 40 # no of eopches to train\n",
    "batch_size = 32 # batch size \n",
    "img_size = 224\n",
    "\n",
    "\n",
    "# result_path  = ''\n",
    "result_path  = 'savemodelandresult\\\\'\n",
    "model_name1 = 'vgg16_correct\\\\model-VGG16-31-0.9400'\n",
    "model_name2 = 'inception_correct\\\\model-InceptionV3-34-0.9325'\n",
    "file_format ='.h5'\n",
    "\n",
    "\n",
    "\n",
    "model_1 = load_model(result_path+model_name1+file_format)\n",
    "model_2 = load_model(result_path+model_name2+file_format)\n",
    "\n",
    "model_1 = Model(inputs=model_1.inputs,\n",
    "                outputs=model_1.outputs,\n",
    "                name='vgg16')\n",
    "\n",
    "model_2 = Model(inputs=model_2.inputs,\n",
    "                outputs=model_2.outputs,\n",
    "                name='inceptionv3')\n",
    "\n",
    "models = [model_1,model_2]\n",
    "model_input = Input(shape=(img_size,img_size,3))\n",
    "model_output = [model(model_input) for model in models]\n",
    "ensemble_output = Average()(model_output)\n",
    "ensemble_model = Model(inputs=model_input,\n",
    "                        outputs=ensemble_output,\n",
    "                        name ='ensemble')\n",
    "\n",
    "\n",
    "#compile our model\n",
    "print(\"compiling model.....\")\n",
    "opt = Adam(learning_rate=initial_lr, decay=initial_lr / epochs)\n",
    "ensemble_model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "ensemble_model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path1  = 'savemodelandresult\\\\vgg16_correct\\\\'\n",
    "model_name = 'model-VGG16-31-0.9400'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testY_data = np.load(result_path1 + 'testY_' + model_name + '.npy')\n",
    "trainY_data = np.load(result_path1 + 'trainY_' + model_name + '.npy')\n",
    "testX_data = np.load(result_path1 + 'testX_' + model_name + '.npy')\n",
    "trainX_data = np.load(result_path1 + 'trainX_' + model_name + '.npy')\n",
    "\n",
    "\n",
    "data_generator_with_aug = ImageDataGenerator(\n",
    "#  rotation_range=45,\n",
    "#  fill_mode=\"nearest\", \n",
    "#  horizontal_flip=True, \n",
    " width_shift_range = 0.1, \n",
    " height_shift_range = 0.1, \n",
    "#  shear_range=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranning head.........\n",
      "Epoch 1/40\n",
      "50/50 [==============================] - 12s 225ms/step - loss: 0.1557 - accuracy: 0.9500 - val_loss: 0.1898 - val_accuracy: 0.9575\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1500 - accuracy: 0.9488 - val_loss: 0.1536 - val_accuracy: 0.9550\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1516 - accuracy: 0.9500 - val_loss: 0.1412 - val_accuracy: 0.9575\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1404 - accuracy: 0.9469 - val_loss: 0.1449 - val_accuracy: 0.9525\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1452 - accuracy: 0.9488 - val_loss: 0.2562 - val_accuracy: 0.8775\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 11s 218ms/step - loss: 0.1543 - accuracy: 0.9481 - val_loss: 0.1893 - val_accuracy: 0.9300\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1445 - accuracy: 0.9463 - val_loss: 0.1371 - val_accuracy: 0.9625\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1598 - accuracy: 0.9488 - val_loss: 0.1690 - val_accuracy: 0.9300\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1338 - accuracy: 0.9494 - val_loss: 0.1545 - val_accuracy: 0.9450\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1334 - accuracy: 0.9544 - val_loss: 0.2158 - val_accuracy: 0.9250\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1401 - accuracy: 0.9494 - val_loss: 0.1505 - val_accuracy: 0.9525\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1378 - accuracy: 0.9500 - val_loss: 0.1597 - val_accuracy: 0.9575\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1412 - accuracy: 0.9444 - val_loss: 0.1459 - val_accuracy: 0.9475\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1438 - accuracy: 0.9463 - val_loss: 0.1744 - val_accuracy: 0.9425\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1396 - accuracy: 0.9544 - val_loss: 0.1679 - val_accuracy: 0.9400\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1347 - accuracy: 0.9531 - val_loss: 0.1434 - val_accuracy: 0.9500\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1345 - accuracy: 0.9544 - val_loss: 0.2113 - val_accuracy: 0.9100\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1477 - accuracy: 0.9544 - val_loss: 0.1586 - val_accuracy: 0.9450\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1272 - accuracy: 0.9588 - val_loss: 0.1849 - val_accuracy: 0.9425\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1603 - accuracy: 0.9438 - val_loss: 0.1462 - val_accuracy: 0.9575\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1356 - accuracy: 0.9544 - val_loss: 0.1451 - val_accuracy: 0.9650\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1350 - accuracy: 0.9569 - val_loss: 0.1459 - val_accuracy: 0.9625\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1397 - accuracy: 0.9538 - val_loss: 0.1395 - val_accuracy: 0.9625\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1323 - accuracy: 0.9538 - val_loss: 0.1370 - val_accuracy: 0.9675\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1201 - accuracy: 0.9550 - val_loss: 0.1357 - val_accuracy: 0.9600\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1224 - accuracy: 0.9631 - val_loss: 0.1380 - val_accuracy: 0.9550\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1260 - accuracy: 0.9581 - val_loss: 0.1321 - val_accuracy: 0.9650\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1131 - accuracy: 0.9619 - val_loss: 0.1547 - val_accuracy: 0.9650\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1059 - accuracy: 0.9631 - val_loss: 0.1717 - val_accuracy: 0.9650\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1287 - accuracy: 0.9600 - val_loss: 0.1767 - val_accuracy: 0.9425\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1321 - accuracy: 0.9575 - val_loss: 0.1400 - val_accuracy: 0.9600\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1289 - accuracy: 0.9538 - val_loss: 0.1430 - val_accuracy: 0.9425\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1157 - accuracy: 0.9531 - val_loss: 0.1584 - val_accuracy: 0.9675\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1456 - accuracy: 0.9538 - val_loss: 0.1616 - val_accuracy: 0.9475\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1346 - accuracy: 0.9531 - val_loss: 0.1706 - val_accuracy: 0.9600\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 11s 216ms/step - loss: 0.1166 - accuracy: 0.9569 - val_loss: 0.1448 - val_accuracy: 0.9450\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 11s 218ms/step - loss: 0.1090 - accuracy: 0.9631 - val_loss: 0.1531 - val_accuracy: 0.9500\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 0.1177 - accuracy: 0.9581 - val_loss: 0.1637 - val_accuracy: 0.9475\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1086 - accuracy: 0.9688 - val_loss: 0.1393 - val_accuracy: 0.9650\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 11s 217ms/step - loss: 0.1026 - accuracy: 0.9663 - val_loss: 0.1409 - val_accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_filepath = \"model-ensemble-{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "\tfilepath=model_filepath,\n",
    "\tmonitor = 'val_accuracy',\n",
    "\tmode='max',\n",
    "\tsave_best_only=True,\n",
    "\tverbose=1\n",
    ")\n",
    "\n",
    "#train the head of the network\n",
    "print(\"tranning head.........\")\n",
    "\n",
    "\n",
    "history = ensemble_model.fit(\n",
    "\t# x=trainX, y=trainY, batch_size= batch_size,\n",
    "\tdata_generator_with_aug.flow(trainX_data, trainY_data, batch_size= batch_size),\n",
    "\tsteps_per_epoch=len(trainX_data) // batch_size,\n",
    "\tvalidation_data = (testX_data, testY_data),\n",
    "\tvalidation_steps = len(testX_data) // batch_size,\n",
    "\tepochs = epochs,\n",
    "\t# callbacks=[checkpoint]\n",
    "\t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b842ee399a034e8441bb1735471026e1a7735de8847d800b5388cb3dc33c04f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
