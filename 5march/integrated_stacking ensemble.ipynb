{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] 1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "  \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import shutil\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "print(\"Num GPUs Available: \", physical_devices, len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.test.gpu_device_name()\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 5\n",
    "lr_rate = 1e-3\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_SHAPE = (224, 224, 3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING IMAGES.......\n",
      "original labels:  covideff\n",
      "original labels:  normaleff\n",
      "original labels to binary:  [0]\n",
      "original labels to binary:  [1]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "initial_lr = 1e-3 # learning rate\n",
    "# epochs = 40 # no of eopches to train\n",
    "# batch_size = 32 # batch size \n",
    "img_size = 224\n",
    "\n",
    "print(\"LOADING IMAGES.......\")\n",
    "imagePaths = list(paths.list_images(\"data\"))\n",
    "data = []\n",
    "labels =[]\n",
    "\n",
    "\n",
    "#loop for the image paths\n",
    "for imagePath in imagePaths:\n",
    "\t#extract the class label from the file\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "\t#load the image\n",
    "\t#swap color channels and resize it\n",
    "\t#fixed 224*224 pixels while ingorning aspect ratio\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (img_size, img_size))\n",
    "\n",
    "\t#update the data and labes lists\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n",
    "\n",
    "print(\"original labels: \", labels[0])\n",
    "print(\"original labels: \", labels[-1])\n",
    "# print(\"original labels to binary: \",labels)\n",
    "\n",
    "#convert the data and labels to numpay\n",
    "#while scalling the pixel to the range [0, 1]\n",
    "data = np.array(data) / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "# performs one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "\n",
    "print(\"original labels to binary: \",labels[0])\n",
    "print(\"original labels to binary: \",labels[-1])\n",
    "# print(\"original labels to binary: \",labels)\n",
    "\n",
    "# labels = to_categorical(labels)\n",
    "# print(\"binary labels to category: \", labels[0])\n",
    "# print(\"binary labels to category: \", labels[-1])\n",
    "# print(\"binary labels to category: \", labels)\n",
    "\n",
    "#partition the data for tranning(80%)\n",
    "#and testing(20%) using splits\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "data_generator_with_aug = ImageDataGenerator(\n",
    "#  rotation_range=45,\n",
    "#  fill_mode=\"nearest\", \n",
    "#  horizontal_flip=True, \n",
    " width_shift_range = 0.1, \n",
    " height_shift_range = 0.1, \n",
    "#  shear_range=16\n",
    ")\n",
    "\n",
    "\n",
    "# data_generator_with_aug = ImageDataGenerator()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(testX)\n",
    "# data_generator_with_aug.fit(trainX)\n",
    "# print(plt.imshow(trainX[0]))\n",
    "# print(lb.classes_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for creating, fitting the model and plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def create_model(baseModel):\n",
    "    baseModel.trainable=False  # all base weight set to non-trainable\n",
    "    #constructing the head of the model that will be placed\n",
    "    #on the top of the model\n",
    "    headModel = baseModel.output\n",
    "    headModel = layers.GlobalAveragePooling2D()(headModel)\n",
    "    # headModel = Flatten(name=\"flatten\")(headModel)\n",
    "    headModel = Dense(1024, activation=\"relu\")(headModel)\n",
    "    headModel = Dropout(0.2)(headModel)\n",
    "    # headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "    headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "    #place the head FC model on top of the base model\n",
    "    #it will become the actual model will be train\n",
    "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "    # #loop over all layers in the base model \n",
    "    # for layer in baseModel.layers:\n",
    "    # \tlayer.trainable = False\n",
    "    #compile our model\n",
    "    print(\"compiling model.....\")\n",
    "    opt = Adam(learning_rate=initial_lr, decay=initial_lr / epochs)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def fit_model(model,model_filepath):\n",
    "    checkpoint = ModelCheckpoint(\n",
    "                filepath=model_filepath,\n",
    "                monitor = 'val_accuracy',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                verbose=1\n",
    "                )\n",
    "    history = model.fit(\n",
    "            trainX, trainY,\n",
    "            batch_size=batch_size,\n",
    "            steps_per_epoch=len(trainX) // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(testX, testY),\n",
    "            validation_steps=len(testX) // batch_size,\n",
    "            callbacks=[checkpoint]\n",
    "            )\n",
    "    return history\n",
    "\n",
    "# def plot_history(history):\n",
    "#     acc = history.history['accuracy']\n",
    "#     val_acc = history.history['val_accuracy']\n",
    "\n",
    "#     loss=history.history['loss']\n",
    "#     val_loss=history.history['val_loss']\n",
    "\n",
    "#     epochs_range = range(epochs)\n",
    "\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "#     plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.title('Training and Validation Accuracy')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(epochs_range, loss, label='Training Loss')\n",
    "#     plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "#     plt.legend(loc='upper right')\n",
    "#     plt.title('Training and Validation Loss')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling model.....\n",
      "compiling model.....\n"
     ]
    }
   ],
   "source": [
    "base_model1 = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE, include_top=False, weights=\"imagenet\")\n",
    "base_model2 = tf.keras.applications.VGG16(input_shape=IMG_SHAPE, include_top=False, weights=\"imagenet\")\n",
    "\n",
    "model1 = create_model(base_model1)\n",
    "model2 = create_model(base_model2)\n",
    "\n",
    "model_saved_folder_path = 'model_saved\\\\'\n",
    "model_weight_path = 'weight\\\\'\n",
    "\n",
    "model_filepath1 = model_saved_folder_path + model_weight_path + \"model-InceptionV3-{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "model_filepath2 = model_saved_folder_path + model_weight_path + \"model-VGG16-{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 111, 111, 32) 864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 111, 111, 32) 96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 111, 111, 32) 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 109, 109, 32) 9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 109, 109, 32) 96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 109, 109, 32) 0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 109, 109, 64) 18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 109, 109, 64) 192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 109, 109, 64) 0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 54, 54, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 54, 54, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 52, 52, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 52, 52, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 52, 52, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 25, 25, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 25, 25, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 25, 25, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 25, 25, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 25, 25, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 25, 25, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 25, 25, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 25, 25, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 25, 25, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 25, 25, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 25, 25, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 25, 25, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 25, 25, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 25, 25, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 25, 25, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 25, 25, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 25, 25, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 25, 25, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 25, 25, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 25, 25, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 25, 25, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 25, 25, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 25, 25, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 25, 25, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 25, 25, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 25, 25, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 25, 25, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 25, 25, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 25, 25, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 25, 25, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 25, 25, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 25, 25, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 25, 25, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 25, 25, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 25, 25, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 25, 25, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 25, 25, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 25, 25, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 25, 25, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 25, 25, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 25, 25, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 25, 25, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 25, 25, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 25, 25, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 25, 25, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 25, 25, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 25, 25, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 25, 25, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 25, 25, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 25, 25, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 25, 25, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 25, 25, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 25, 25, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 25, 25, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 25, 25, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 25, 25, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 12, 12, 96)   82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 12, 12, 384)  1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 12, 12, 96)   288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 12, 12, 384)  0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 12, 12, 96)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 12, 12, 128)  384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 12, 12, 128)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 12, 12, 128)  114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 12, 12, 128)  384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 12, 12, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 12, 12, 128)  114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 12, 12, 128)  384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 12, 12, 128)  384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 12, 12, 128)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 12, 12, 128)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 12, 12, 128)  114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 12, 12, 128)  114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 12, 12, 128)  384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 12, 12, 128)  384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 12, 12, 128)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 12, 12, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 12, 12, 192)  172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 12, 12, 192)  172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 12, 12, 192)  576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 12, 12, 192)  576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 12, 12, 192)  576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 12, 12, 192)  576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 12, 12, 192)  0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 12, 12, 192)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 12, 12, 192)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 12, 12, 192)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 12, 12, 160)  480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 12, 12, 160)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 12, 12, 160)  179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 12, 12, 160)  480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 12, 12, 160)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 12, 12, 160)  179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 12, 12, 160)  480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 12, 12, 160)  480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 12, 12, 160)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 12, 12, 160)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 12, 12, 160)  179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 12, 12, 160)  179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 12, 12, 160)  480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 12, 12, 160)  480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 12, 12, 160)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 12, 12, 160)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 12, 12, 192)  215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 12, 12, 192)  215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 12, 12, 192)  576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 12, 12, 192)  576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 12, 12, 192)  576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 12, 12, 192)  576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 12, 12, 192)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 12, 12, 192)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 12, 12, 192)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 12, 12, 192)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 12, 12, 160)  480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 12, 12, 160)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 12, 12, 160)  179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 12, 12, 160)  480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 12, 12, 160)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 12, 12, 160)  179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 12, 12, 160)  480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 12, 12, 160)  480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 12, 12, 160)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 12, 12, 160)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 12, 12, 160)  179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 12, 12, 160)  179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 12, 12, 160)  480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 12, 12, 160)  480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 12, 12, 160)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 12, 12, 160)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 12, 12, 192)  215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 12, 12, 192)  215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 12, 12, 192)  576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 12, 12, 192)  576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 12, 12, 192)  576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 12, 12, 192)  576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 12, 12, 192)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 12, 12, 192)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 12, 12, 192)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 12, 12, 192)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 12, 12, 192)  576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 12, 12, 192)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 12, 12, 192)  258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 12, 12, 192)  576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 12, 12, 192)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 12, 12, 192)  258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 12, 12, 192)  576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 12, 12, 192)  576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 12, 12, 192)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 12, 12, 192)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 12, 12, 192)  258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 12, 12, 192)  258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 12, 12, 192)  576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 12, 12, 192)  576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 12, 12, 192)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 12, 12, 192)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 12, 12, 192)  258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 12, 12, 192)  258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 12, 12, 192)  576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 12, 12, 192)  576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 12, 12, 192)  576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 12, 12, 192)  576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 12, 12, 192)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 12, 12, 192)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 12, 12, 192)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 12, 12, 192)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 12, 12, 192)  576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 12, 12, 192)  0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 12, 12, 192)  258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 12, 12, 192)  576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 12, 12, 192)  0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 12, 12, 192)  258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 12, 12, 192)  576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 12, 12, 192)  576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 12, 12, 192)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 12, 12, 192)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 5, 5, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 5, 5, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 5, 5, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 5, 5, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 5, 5, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 5, 5, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 5, 5, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 5, 5, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 5, 5, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 5, 5, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 5, 5, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 5, 5, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 5, 5, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 5, 5, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 5, 5, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 5, 5, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 5, 5, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 5, 5, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 5, 5, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 5, 5, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 5, 5, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 5, 5, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 5, 5, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 5, 5, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 5, 5, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 5, 5, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 5, 5, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 5, 5, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 5, 5, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_264[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 5, 5, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 5, 5, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 5, 5, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 5, 5, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 5, 5, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 5, 5, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 5, 5, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 5, 5, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 5, 5, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 5, 5, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 5, 5, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 5, 5, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 5, 5, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 5, 5, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 5, 5, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 5, 5, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 5, 5, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 5, 5, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 5, 5, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 5, 5, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 5, 5, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 5, 5, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 5, 5, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_273[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            2050        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tranning head.........\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 13s 29ms/step - loss: 0.5942 - accuracy: 0.7812 - val_loss: 0.4755 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76250, saving model to model_saved\\weight\\model-InceptionV3-01-0.7625.h5\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.3090 - accuracy: 0.8712 - val_loss: 0.2759 - val_accuracy: 0.8875\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.76250 to 0.88750, saving model to model_saved\\weight\\model-InceptionV3-02-0.8875.h5\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.2776 - accuracy: 0.8737 - val_loss: 0.2833 - val_accuracy: 0.8825\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.88750\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.2618 - accuracy: 0.8969 - val_loss: 0.2771 - val_accuracy: 0.8825\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.88750\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.2180 - accuracy: 0.9050 - val_loss: 0.3804 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.88750\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 9s 37ms/step - loss: 0.4834 - accuracy: 0.7713 - val_loss: 0.5345 - val_accuracy: 0.7525\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75250, saving model to model_saved\\weight\\model-VGG16-01-0.7525.h5\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.3593 - accuracy: 0.8481 - val_loss: 0.2866 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.75250 to 0.89250, saving model to model_saved\\weight\\model-VGG16-02-0.8925.h5\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.3373 - accuracy: 0.8569 - val_loss: 0.3809 - val_accuracy: 0.8300\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.89250\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.2947 - accuracy: 0.8750 - val_loss: 0.2782 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.89250\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.2815 - accuracy: 0.8825 - val_loss: 0.2344 - val_accuracy: 0.9100\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.89250 to 0.91000, saving model to model_saved\\weight\\model-VGG16-05-0.9100.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#train the head of the network\n",
    "print(\"tranning head.........\")\n",
    "history1 = fit_model(model1, model_filepath1)\n",
    "history2 = fit_model(model2, model_filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history1)\n",
    "plot_history(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_models(model_path_name):\n",
    "    all_models = []\n",
    "    # model_path_name = []\n",
    "    model_names = model_path_name\n",
    "    for model_name in model_names:\n",
    "        filename = os.path.join(model_name)\n",
    "        model = tf.keras.models.load_model(filename)\n",
    "        all_models.append(model)\n",
    "        print('loaded:', filename)\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "def ensemble_model(models):\n",
    "        # model1.summary()\n",
    "\n",
    "    # models[0].layers[0]._name = models[0].layers[0]._name + \"inc\"\n",
    "    # models[1].layers[0]._name = models[1].layers[0]._name + \"inc\"\n",
    "\n",
    "    for i, layer in enumerate(models[0].layers):\n",
    "        layer._name = models[0].layers[i]._name + \"_inc\"\n",
    "    for i, layer in enumerate(models[1].layers):\n",
    "        layer._name = models[1].layers[i]._name + \"_vgg\"\n",
    "\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "            from tensorflow.keras import layers\n",
    "\n",
    "    ensemble_visible = [model.input for model in models]\n",
    "    ensemble_outputs = [model.output for model in models]\n",
    "    merge = tf.keras.layers.concatenate(ensemble_outputs)\n",
    "    merge = tf.keras.layers.Dense(10, activation='relu')(merge)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(merge)\n",
    "    model = tf.keras.models.Model(inputs=ensemble_visible, outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_saved\\\\weight\\\\model-InceptionV3-02-0.8875.h5', 'model_saved\\\\weight\\\\model-VGG16-05-0.9100.h5']\n",
      "loaded: model_saved\\weight\\model-InceptionV3-02-0.8875.h5\n",
      "loaded: model_saved\\weight\\model-VGG16-05-0.9100.h5\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1_inc (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_inc (Conv2D)             (None, 111, 111, 32) 864         input_1_inc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_inc (BatchN (None, 111, 111, 32) 96          conv2d_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_inc (Activation)     (None, 111, 111, 32) 0           batch_normalization_inc[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1_inc (Conv2D)           (None, 109, 109, 32) 9216        activation_inc[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1_inc (Batc (None, 109, 109, 32) 96          conv2d_1_inc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1_inc (Activation)   (None, 109, 109, 32) 0           batch_normalization_1_inc[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2_inc (Conv2D)           (None, 109, 109, 64) 18432       activation_1_inc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2_inc (Batc (None, 109, 109, 64) 192         conv2d_2_inc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2_inc (Activation)   (None, 109, 109, 64) 0           batch_normalization_2_inc[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_inc (MaxPooling2D (None, 54, 54, 64)   0           activation_2_inc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3_inc (Conv2D)           (None, 54, 54, 80)   5120        max_pooling2d_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3_inc (Batc (None, 54, 54, 80)   240         conv2d_3_inc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3_inc (Activation)   (None, 54, 54, 80)   0           batch_normalization_3_inc[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4_inc (Conv2D)           (None, 52, 52, 192)  138240      activation_3_inc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4_inc (Batc (None, 52, 52, 192)  576         conv2d_4_inc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4_inc (Activation)   (None, 52, 52, 192)  0           batch_normalization_4_inc[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1_inc (MaxPooling (None, 25, 25, 192)  0           activation_4_inc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8_inc (Conv2D)           (None, 25, 25, 64)   12288       max_pooling2d_1_inc[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8_inc (Batc (None, 25, 25, 64)   192         conv2d_8_inc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8_inc (Activation)   (None, 25, 25, 64)   0           batch_normalization_8_inc[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6_inc (Conv2D)           (None, 25, 25, 48)   9216        max_pooling2d_1_inc[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9_inc (Conv2D)           (None, 25, 25, 96)   55296       activation_8_inc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6_inc (Batc (None, 25, 25, 48)   144         conv2d_6_inc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9_inc (Batc (None, 25, 25, 96)   288         conv2d_9_inc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6_inc (Activation)   (None, 25, 25, 48)   0           batch_normalization_6_inc[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9_inc (Activation)   (None, 25, 25, 96)   0           batch_normalization_9_inc[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_inc (AverageP (None, 25, 25, 192)  0           max_pooling2d_1_inc[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5_inc (Conv2D)           (None, 25, 25, 64)   12288       max_pooling2d_1_inc[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7_inc (Conv2D)           (None, 25, 25, 64)   76800       activation_6_inc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10_inc (Conv2D)          (None, 25, 25, 96)   82944       activation_9_inc[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11_inc (Conv2D)          (None, 25, 25, 32)   6144        average_pooling2d_inc[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5_inc (Batc (None, 25, 25, 64)   192         conv2d_5_inc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7_inc (Batc (None, 25, 25, 64)   192         conv2d_7_inc[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10_inc (Bat (None, 25, 25, 96)   288         conv2d_10_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11_inc (Bat (None, 25, 25, 32)   96          conv2d_11_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5_inc (Activation)   (None, 25, 25, 64)   0           batch_normalization_5_inc[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7_inc (Activation)   (None, 25, 25, 64)   0           batch_normalization_7_inc[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10_inc (Activation)  (None, 25, 25, 96)   0           batch_normalization_10_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_11_inc (Activation)  (None, 25, 25, 32)   0           batch_normalization_11_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed0_inc (Concatenate)        (None, 25, 25, 256)  0           activation_5_inc[0][0]           \n",
      "                                                                 activation_7_inc[0][0]           \n",
      "                                                                 activation_10_inc[0][0]          \n",
      "                                                                 activation_11_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15_inc (Conv2D)          (None, 25, 25, 64)   16384       mixed0_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15_inc (Bat (None, 25, 25, 64)   192         conv2d_15_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15_inc (Activation)  (None, 25, 25, 64)   0           batch_normalization_15_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13_inc (Conv2D)          (None, 25, 25, 48)   12288       mixed0_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16_inc (Conv2D)          (None, 25, 25, 96)   55296       activation_15_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13_inc (Bat (None, 25, 25, 48)   144         conv2d_13_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16_inc (Bat (None, 25, 25, 96)   288         conv2d_16_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13_inc (Activation)  (None, 25, 25, 48)   0           batch_normalization_13_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_16_inc (Activation)  (None, 25, 25, 96)   0           batch_normalization_16_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1_inc (Averag (None, 25, 25, 256)  0           mixed0_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12_inc (Conv2D)          (None, 25, 25, 64)   16384       mixed0_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14_inc (Conv2D)          (None, 25, 25, 64)   76800       activation_13_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17_inc (Conv2D)          (None, 25, 25, 96)   82944       activation_16_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18_inc (Conv2D)          (None, 25, 25, 64)   16384       average_pooling2d_1_inc[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12_inc (Bat (None, 25, 25, 64)   192         conv2d_12_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14_inc (Bat (None, 25, 25, 64)   192         conv2d_14_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17_inc (Bat (None, 25, 25, 96)   288         conv2d_17_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18_inc (Bat (None, 25, 25, 64)   192         conv2d_18_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12_inc (Activation)  (None, 25, 25, 64)   0           batch_normalization_12_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_14_inc (Activation)  (None, 25, 25, 64)   0           batch_normalization_14_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_17_inc (Activation)  (None, 25, 25, 96)   0           batch_normalization_17_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_18_inc (Activation)  (None, 25, 25, 64)   0           batch_normalization_18_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed1_inc (Concatenate)        (None, 25, 25, 288)  0           activation_12_inc[0][0]          \n",
      "                                                                 activation_14_inc[0][0]          \n",
      "                                                                 activation_17_inc[0][0]          \n",
      "                                                                 activation_18_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22_inc (Conv2D)          (None, 25, 25, 64)   18432       mixed1_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22_inc (Bat (None, 25, 25, 64)   192         conv2d_22_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22_inc (Activation)  (None, 25, 25, 64)   0           batch_normalization_22_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20_inc (Conv2D)          (None, 25, 25, 48)   13824       mixed1_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23_inc (Conv2D)          (None, 25, 25, 96)   55296       activation_22_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20_inc (Bat (None, 25, 25, 48)   144         conv2d_20_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23_inc (Bat (None, 25, 25, 96)   288         conv2d_23_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20_inc (Activation)  (None, 25, 25, 48)   0           batch_normalization_20_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_23_inc (Activation)  (None, 25, 25, 96)   0           batch_normalization_23_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2_inc (Averag (None, 25, 25, 288)  0           mixed1_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19_inc (Conv2D)          (None, 25, 25, 64)   18432       mixed1_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21_inc (Conv2D)          (None, 25, 25, 64)   76800       activation_20_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24_inc (Conv2D)          (None, 25, 25, 96)   82944       activation_23_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25_inc (Conv2D)          (None, 25, 25, 64)   18432       average_pooling2d_2_inc[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19_inc (Bat (None, 25, 25, 64)   192         conv2d_19_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21_inc (Bat (None, 25, 25, 64)   192         conv2d_21_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24_inc (Bat (None, 25, 25, 96)   288         conv2d_24_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25_inc (Bat (None, 25, 25, 64)   192         conv2d_25_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19_inc (Activation)  (None, 25, 25, 64)   0           batch_normalization_19_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_21_inc (Activation)  (None, 25, 25, 64)   0           batch_normalization_21_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_24_inc (Activation)  (None, 25, 25, 96)   0           batch_normalization_24_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_25_inc (Activation)  (None, 25, 25, 64)   0           batch_normalization_25_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed2_inc (Concatenate)        (None, 25, 25, 288)  0           activation_19_inc[0][0]          \n",
      "                                                                 activation_21_inc[0][0]          \n",
      "                                                                 activation_24_inc[0][0]          \n",
      "                                                                 activation_25_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27_inc (Conv2D)          (None, 25, 25, 64)   18432       mixed2_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27_inc (Bat (None, 25, 25, 64)   192         conv2d_27_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27_inc (Activation)  (None, 25, 25, 64)   0           batch_normalization_27_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28_inc (Conv2D)          (None, 25, 25, 96)   55296       activation_27_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28_inc (Bat (None, 25, 25, 96)   288         conv2d_28_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28_inc (Activation)  (None, 25, 25, 96)   0           batch_normalization_28_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26_inc (Conv2D)          (None, 12, 12, 384)  995328      mixed2_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29_inc (Conv2D)          (None, 12, 12, 96)   82944       activation_28_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26_inc (Bat (None, 12, 12, 384)  1152        conv2d_26_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29_inc (Bat (None, 12, 12, 96)   288         conv2d_29_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26_inc (Activation)  (None, 12, 12, 384)  0           batch_normalization_26_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_29_inc (Activation)  (None, 12, 12, 96)   0           batch_normalization_29_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2_inc (MaxPooling (None, 12, 12, 288)  0           mixed2_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed3_inc (Concatenate)        (None, 12, 12, 768)  0           activation_26_inc[0][0]          \n",
      "                                                                 activation_29_inc[0][0]          \n",
      "                                                                 max_pooling2d_2_inc[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34_inc (Conv2D)          (None, 12, 12, 128)  98304       mixed3_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34_inc (Bat (None, 12, 12, 128)  384         conv2d_34_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34_inc (Activation)  (None, 12, 12, 128)  0           batch_normalization_34_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35_inc (Conv2D)          (None, 12, 12, 128)  114688      activation_34_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35_inc (Bat (None, 12, 12, 128)  384         conv2d_35_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35_inc (Activation)  (None, 12, 12, 128)  0           batch_normalization_35_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31_inc (Conv2D)          (None, 12, 12, 128)  98304       mixed3_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36_inc (Conv2D)          (None, 12, 12, 128)  114688      activation_35_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31_inc (Bat (None, 12, 12, 128)  384         conv2d_31_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36_inc (Bat (None, 12, 12, 128)  384         conv2d_36_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31_inc (Activation)  (None, 12, 12, 128)  0           batch_normalization_31_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_36_inc (Activation)  (None, 12, 12, 128)  0           batch_normalization_36_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32_inc (Conv2D)          (None, 12, 12, 128)  114688      activation_31_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37_inc (Conv2D)          (None, 12, 12, 128)  114688      activation_36_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32_inc (Bat (None, 12, 12, 128)  384         conv2d_32_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37_inc (Bat (None, 12, 12, 128)  384         conv2d_37_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32_inc (Activation)  (None, 12, 12, 128)  0           batch_normalization_32_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_37_inc (Activation)  (None, 12, 12, 128)  0           batch_normalization_37_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3_inc (Averag (None, 12, 12, 768)  0           mixed3_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30_inc (Conv2D)          (None, 12, 12, 192)  147456      mixed3_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33_inc (Conv2D)          (None, 12, 12, 192)  172032      activation_32_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38_inc (Conv2D)          (None, 12, 12, 192)  172032      activation_37_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39_inc (Conv2D)          (None, 12, 12, 192)  147456      average_pooling2d_3_inc[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30_inc (Bat (None, 12, 12, 192)  576         conv2d_30_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33_inc (Bat (None, 12, 12, 192)  576         conv2d_33_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38_inc (Bat (None, 12, 12, 192)  576         conv2d_38_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39_inc (Bat (None, 12, 12, 192)  576         conv2d_39_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_30_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_33_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_33_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_38_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_38_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_39_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_39_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed4_inc (Concatenate)        (None, 12, 12, 768)  0           activation_30_inc[0][0]          \n",
      "                                                                 activation_33_inc[0][0]          \n",
      "                                                                 activation_38_inc[0][0]          \n",
      "                                                                 activation_39_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44_inc (Conv2D)          (None, 12, 12, 160)  122880      mixed4_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44_inc (Bat (None, 12, 12, 160)  480         conv2d_44_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_44_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_44_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45_inc (Conv2D)          (None, 12, 12, 160)  179200      activation_44_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45_inc (Bat (None, 12, 12, 160)  480         conv2d_45_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_45_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41_inc (Conv2D)          (None, 12, 12, 160)  122880      mixed4_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46_inc (Conv2D)          (None, 12, 12, 160)  179200      activation_45_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41_inc (Bat (None, 12, 12, 160)  480         conv2d_41_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46_inc (Bat (None, 12, 12, 160)  480         conv2d_46_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_41_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_46_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_46_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42_inc (Conv2D)          (None, 12, 12, 160)  179200      activation_41_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47_inc (Conv2D)          (None, 12, 12, 160)  179200      activation_46_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42_inc (Bat (None, 12, 12, 160)  480         conv2d_42_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47_inc (Bat (None, 12, 12, 160)  480         conv2d_47_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_42_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_47_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_47_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4_inc (Averag (None, 12, 12, 768)  0           mixed4_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40_inc (Conv2D)          (None, 12, 12, 192)  147456      mixed4_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43_inc (Conv2D)          (None, 12, 12, 192)  215040      activation_42_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48_inc (Conv2D)          (None, 12, 12, 192)  215040      activation_47_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49_inc (Conv2D)          (None, 12, 12, 192)  147456      average_pooling2d_4_inc[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40_inc (Bat (None, 12, 12, 192)  576         conv2d_40_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43_inc (Bat (None, 12, 12, 192)  576         conv2d_43_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48_inc (Bat (None, 12, 12, 192)  576         conv2d_48_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49_inc (Bat (None, 12, 12, 192)  576         conv2d_49_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_40_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_43_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_43_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_48_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_48_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_49_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_49_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed5_inc (Concatenate)        (None, 12, 12, 768)  0           activation_40_inc[0][0]          \n",
      "                                                                 activation_43_inc[0][0]          \n",
      "                                                                 activation_48_inc[0][0]          \n",
      "                                                                 activation_49_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54_inc (Conv2D)          (None, 12, 12, 160)  122880      mixed5_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54_inc (Bat (None, 12, 12, 160)  480         conv2d_54_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_54_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55_inc (Conv2D)          (None, 12, 12, 160)  179200      activation_54_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55_inc (Bat (None, 12, 12, 160)  480         conv2d_55_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_55_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51_inc (Conv2D)          (None, 12, 12, 160)  122880      mixed5_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56_inc (Conv2D)          (None, 12, 12, 160)  179200      activation_55_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51_inc (Bat (None, 12, 12, 160)  480         conv2d_51_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56_inc (Bat (None, 12, 12, 160)  480         conv2d_56_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_51_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_56_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_56_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52_inc (Conv2D)          (None, 12, 12, 160)  179200      activation_51_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57_inc (Conv2D)          (None, 12, 12, 160)  179200      activation_56_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52_inc (Bat (None, 12, 12, 160)  480         conv2d_52_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57_inc (Bat (None, 12, 12, 160)  480         conv2d_57_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_52_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_57_inc (Activation)  (None, 12, 12, 160)  0           batch_normalization_57_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5_inc (Averag (None, 12, 12, 768)  0           mixed5_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50_inc (Conv2D)          (None, 12, 12, 192)  147456      mixed5_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53_inc (Conv2D)          (None, 12, 12, 192)  215040      activation_52_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58_inc (Conv2D)          (None, 12, 12, 192)  215040      activation_57_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59_inc (Conv2D)          (None, 12, 12, 192)  147456      average_pooling2d_5_inc[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50_inc (Bat (None, 12, 12, 192)  576         conv2d_50_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53_inc (Bat (None, 12, 12, 192)  576         conv2d_53_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58_inc (Bat (None, 12, 12, 192)  576         conv2d_58_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59_inc (Bat (None, 12, 12, 192)  576         conv2d_59_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_50_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_53_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_53_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_58_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_58_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_59_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_59_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed6_inc (Concatenate)        (None, 12, 12, 768)  0           activation_50_inc[0][0]          \n",
      "                                                                 activation_53_inc[0][0]          \n",
      "                                                                 activation_58_inc[0][0]          \n",
      "                                                                 activation_59_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64_inc (Conv2D)          (None, 12, 12, 192)  147456      mixed6_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64_inc (Bat (None, 12, 12, 192)  576         conv2d_64_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_64_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65_inc (Conv2D)          (None, 12, 12, 192)  258048      activation_64_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65_inc (Bat (None, 12, 12, 192)  576         conv2d_65_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_65_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61_inc (Conv2D)          (None, 12, 12, 192)  147456      mixed6_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66_inc (Conv2D)          (None, 12, 12, 192)  258048      activation_65_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61_inc (Bat (None, 12, 12, 192)  576         conv2d_61_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66_inc (Bat (None, 12, 12, 192)  576         conv2d_66_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_61_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_66_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_66_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62_inc (Conv2D)          (None, 12, 12, 192)  258048      activation_61_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67_inc (Conv2D)          (None, 12, 12, 192)  258048      activation_66_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62_inc (Bat (None, 12, 12, 192)  576         conv2d_62_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67_inc (Bat (None, 12, 12, 192)  576         conv2d_67_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_62_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_67_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_67_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6_inc (Averag (None, 12, 12, 768)  0           mixed6_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60_inc (Conv2D)          (None, 12, 12, 192)  147456      mixed6_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63_inc (Conv2D)          (None, 12, 12, 192)  258048      activation_62_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68_inc (Conv2D)          (None, 12, 12, 192)  258048      activation_67_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69_inc (Conv2D)          (None, 12, 12, 192)  147456      average_pooling2d_6_inc[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60_inc (Bat (None, 12, 12, 192)  576         conv2d_60_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63_inc (Bat (None, 12, 12, 192)  576         conv2d_63_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68_inc (Bat (None, 12, 12, 192)  576         conv2d_68_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69_inc (Bat (None, 12, 12, 192)  576         conv2d_69_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_60_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_63_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_63_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_68_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_68_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_69_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_69_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed7_inc (Concatenate)        (None, 12, 12, 768)  0           activation_60_inc[0][0]          \n",
      "                                                                 activation_63_inc[0][0]          \n",
      "                                                                 activation_68_inc[0][0]          \n",
      "                                                                 activation_69_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72_inc (Conv2D)          (None, 12, 12, 192)  147456      mixed7_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72_inc (Bat (None, 12, 12, 192)  576         conv2d_72_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_72_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73_inc (Conv2D)          (None, 12, 12, 192)  258048      activation_72_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73_inc (Bat (None, 12, 12, 192)  576         conv2d_73_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_73_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_73_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70_inc (Conv2D)          (None, 12, 12, 192)  147456      mixed7_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74_inc (Conv2D)          (None, 12, 12, 192)  258048      activation_73_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70_inc (Bat (None, 12, 12, 192)  576         conv2d_70_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74_inc (Bat (None, 12, 12, 192)  576         conv2d_74_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_70_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_74_inc (Activation)  (None, 12, 12, 192)  0           batch_normalization_74_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71_inc (Conv2D)          (None, 5, 5, 320)    552960      activation_70_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75_inc (Conv2D)          (None, 5, 5, 192)    331776      activation_74_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71_inc (Bat (None, 5, 5, 320)    960         conv2d_71_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75_inc (Bat (None, 5, 5, 192)    576         conv2d_75_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71_inc (Activation)  (None, 5, 5, 320)    0           batch_normalization_71_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_75_inc (Activation)  (None, 5, 5, 192)    0           batch_normalization_75_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3_inc (MaxPooling (None, 5, 5, 768)    0           mixed7_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed8_inc (Concatenate)        (None, 5, 5, 1280)   0           activation_71_inc[0][0]          \n",
      "                                                                 activation_75_inc[0][0]          \n",
      "                                                                 max_pooling2d_3_inc[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80_inc (Conv2D)          (None, 5, 5, 448)    573440      mixed8_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80_inc (Bat (None, 5, 5, 448)    1344        conv2d_80_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80_inc (Activation)  (None, 5, 5, 448)    0           batch_normalization_80_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77_inc (Conv2D)          (None, 5, 5, 384)    491520      mixed8_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81_inc (Conv2D)          (None, 5, 5, 384)    1548288     activation_80_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_2_vgg (InputLayer)        [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77_inc (Bat (None, 5, 5, 384)    1152        conv2d_77_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81_inc (Bat (None, 5, 5, 384)    1152        conv2d_81_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_vgg (Conv2D)       (None, 224, 224, 64) 1792        input_2_vgg[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_77_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_77_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_81_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_81_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_vgg (Conv2D)       (None, 224, 224, 64) 36928       block1_conv1_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78_inc (Conv2D)          (None, 5, 5, 384)    442368      activation_77_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79_inc (Conv2D)          (None, 5, 5, 384)    442368      activation_77_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82_inc (Conv2D)          (None, 5, 5, 384)    442368      activation_81_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83_inc (Conv2D)          (None, 5, 5, 384)    442368      activation_81_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7_inc (Averag (None, 5, 5, 1280)   0           mixed8_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool_vgg (MaxPooling2D)  (None, 112, 112, 64) 0           block1_conv2_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76_inc (Conv2D)          (None, 5, 5, 320)    409600      mixed8_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78_inc (Bat (None, 5, 5, 384)    1152        conv2d_78_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79_inc (Bat (None, 5, 5, 384)    1152        conv2d_79_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82_inc (Bat (None, 5, 5, 384)    1152        conv2d_82_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83_inc (Bat (None, 5, 5, 384)    1152        conv2d_83_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84_inc (Conv2D)          (None, 5, 5, 192)    245760      average_pooling2d_7_inc[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1_vgg (Conv2D)       (None, 112, 112, 128 73856       block1_pool_vgg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76_inc (Bat (None, 5, 5, 320)    960         conv2d_76_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_78_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_78_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_79_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_79_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_82_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_82_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_83_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_83_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84_inc (Bat (None, 5, 5, 192)    576         conv2d_84_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2_vgg (Conv2D)       (None, 112, 112, 128 147584      block2_conv1_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_76_inc (Activation)  (None, 5, 5, 320)    0           batch_normalization_76_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0_inc (Concatenate)      (None, 5, 5, 768)    0           activation_78_inc[0][0]          \n",
      "                                                                 activation_79_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_inc (Concatenate)   (None, 5, 5, 768)    0           activation_82_inc[0][0]          \n",
      "                                                                 activation_83_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_84_inc (Activation)  (None, 5, 5, 192)    0           batch_normalization_84_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool_vgg (MaxPooling2D)  (None, 56, 56, 128)  0           block2_conv2_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_inc (Concatenate)        (None, 5, 5, 2048)   0           activation_76_inc[0][0]          \n",
      "                                                                 mixed9_0_inc[0][0]               \n",
      "                                                                 concatenate_inc[0][0]            \n",
      "                                                                 activation_84_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1_vgg (Conv2D)       (None, 56, 56, 256)  295168      block2_pool_vgg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89_inc (Conv2D)          (None, 5, 5, 448)    917504      mixed9_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2_vgg (Conv2D)       (None, 56, 56, 256)  590080      block3_conv1_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89_inc (Bat (None, 5, 5, 448)    1344        conv2d_89_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3_vgg (Conv2D)       (None, 56, 56, 256)  590080      block3_conv2_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_89_inc (Activation)  (None, 5, 5, 448)    0           batch_normalization_89_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool_vgg (MaxPooling2D)  (None, 28, 28, 256)  0           block3_conv3_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86_inc (Conv2D)          (None, 5, 5, 384)    786432      mixed9_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90_inc (Conv2D)          (None, 5, 5, 384)    1548288     activation_89_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1_vgg (Conv2D)       (None, 28, 28, 512)  1180160     block3_pool_vgg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86_inc (Bat (None, 5, 5, 384)    1152        conv2d_86_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90_inc (Bat (None, 5, 5, 384)    1152        conv2d_90_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2_vgg (Conv2D)       (None, 28, 28, 512)  2359808     block4_conv1_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_86_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_86_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_90_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_90_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3_vgg (Conv2D)       (None, 28, 28, 512)  2359808     block4_conv2_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87_inc (Conv2D)          (None, 5, 5, 384)    442368      activation_86_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88_inc (Conv2D)          (None, 5, 5, 384)    442368      activation_86_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91_inc (Conv2D)          (None, 5, 5, 384)    442368      activation_90_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92_inc (Conv2D)          (None, 5, 5, 384)    442368      activation_90_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8_inc (Averag (None, 5, 5, 2048)   0           mixed9_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool_vgg (MaxPooling2D)  (None, 14, 14, 512)  0           block4_conv3_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85_inc (Conv2D)          (None, 5, 5, 320)    655360      mixed9_inc[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87_inc (Bat (None, 5, 5, 384)    1152        conv2d_87_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88_inc (Bat (None, 5, 5, 384)    1152        conv2d_88_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91_inc (Bat (None, 5, 5, 384)    1152        conv2d_91_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92_inc (Bat (None, 5, 5, 384)    1152        conv2d_92_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93_inc (Conv2D)          (None, 5, 5, 192)    393216      average_pooling2d_8_inc[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1_vgg (Conv2D)       (None, 14, 14, 512)  2359808     block4_pool_vgg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85_inc (Bat (None, 5, 5, 320)    960         conv2d_85_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_87_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_87_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_88_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_88_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_91_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_91_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_92_inc (Activation)  (None, 5, 5, 384)    0           batch_normalization_92_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93_inc (Bat (None, 5, 5, 192)    576         conv2d_93_inc[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2_vgg (Conv2D)       (None, 14, 14, 512)  2359808     block5_conv1_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_85_inc (Activation)  (None, 5, 5, 320)    0           batch_normalization_85_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1_inc (Concatenate)      (None, 5, 5, 768)    0           activation_87_inc[0][0]          \n",
      "                                                                 activation_88_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1_inc (Concatenate) (None, 5, 5, 768)    0           activation_91_inc[0][0]          \n",
      "                                                                 activation_92_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_93_inc (Activation)  (None, 5, 5, 192)    0           batch_normalization_93_inc[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3_vgg (Conv2D)       (None, 14, 14, 512)  2359808     block5_conv2_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mixed10_inc (Concatenate)       (None, 5, 5, 2048)   0           activation_85_inc[0][0]          \n",
      "                                                                 mixed9_1_inc[0][0]               \n",
      "                                                                 concatenate_1_inc[0][0]          \n",
      "                                                                 activation_93_inc[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool_vgg (MaxPooling2D)  (None, 7, 7, 512)    0           block5_conv3_vgg[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_inc (G (None, 2048)         0           mixed10_inc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1_vgg  (None, 512)          0           block5_pool_vgg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_inc (Dense)               (None, 1024)         2098176     global_average_pooling2d_inc[0][0\n",
      "__________________________________________________________________________________________________\n",
      "dense_2_vgg (Dense)             (None, 1024)         525312      global_average_pooling2d_1_vgg[0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_inc (Dropout)           (None, 1024)         0           dense_inc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1_vgg (Dropout)         (None, 1024)         0           dense_2_vgg[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_inc (Dense)             (None, 1)            1025        dropout_inc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_vgg (Dense)             (None, 1)            1025        dropout_1_vgg[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2)            0           dense_1_inc[0][0]                \n",
      "                                                                 dense_3_vgg[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           30          concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            11          dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 39,143,051\n",
      "Trainable params: 41\n",
      "Non-trainable params: 39,143,010\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_used = ['InceptionV3', 'VGG16']\n",
    "model_best_acc = ['-02-0.8875','-05-0.9100']\n",
    "\n",
    "model_weight_loaded1 =  model_saved_folder_path + model_weight_path + 'model-' + model_used[0] + model_best_acc[0] + '.h5'\n",
    "model_weight_loaded2 =  model_saved_folder_path + model_weight_path + 'model-' + model_used[1] + model_best_acc[1] + '.h5'\n",
    "model_weight_name =[model_weight_loaded1,model_weight_loaded2]\n",
    "\n",
    "print(model_weight_name)\n",
    "\n",
    "models = load_all_models(model_weight_name)\n",
    "# models.summary()\n",
    "model = ensemble_model(models)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [trainX for _ in range(len(model.input))]\n",
    "X_1 = [testX for _ in range(len(model.input))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:5029: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 21s 61ms/step - loss: 0.5567 - accuracy: 0.7538 - val_loss: 0.5165 - val_accuracy: 0.8150\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81500, saving model to model_saved\\weight\\model-ensemble-01-0.8150.h5\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 0.4742 - accuracy: 0.8719 - val_loss: 0.4468 - val_accuracy: 0.8825\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.81500 to 0.88250, saving model to model_saved\\weight\\model-ensemble-02-0.8825.h5\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 0.4028 - accuracy: 0.9106 - val_loss: 0.3778 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.88250 to 0.91750, saving model to model_saved\\weight\\model-ensemble-03-0.9175.h5\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 0.3349 - accuracy: 0.9275 - val_loss: 0.3170 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91750 to 0.93000, saving model to model_saved\\weight\\model-ensemble-04-0.9300.h5\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 11s 53ms/step - loss: 0.2808 - accuracy: 0.9281 - val_loss: 0.2726 - val_accuracy: 0.9425\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.93000 to 0.94250, saving model to model_saved\\weight\\model-ensemble-05-0.9425.h5\n"
     ]
    }
   ],
   "source": [
    "model_filepath = model_saved_folder_path + model_weight_path + \"model-ensemble-{epoch:02d}-{val_accuracy:.4f}.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "            filepath=model_filepath,\n",
    "            monitor = 'val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "            )\n",
    "history = model.fit(\n",
    "        X, trainY,\n",
    "        batch_size=batch_size,\n",
    "        steps_per_epoch=len(trainX) // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_1, testY),\n",
    "        validation_steps=len(testX) // batch_size,\n",
    "        callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "# from keras.utils import vis_utils\n",
    "import os\n",
    "\n",
    "model1 = models[0]\n",
    "model2 = models[1]\n",
    "\n",
    "summary_save_path = 'model_summary/'\n",
    "### create file here need to manual create folder at window explorer\n",
    "\n",
    "plot_model(model,to_file= summary_save_path + 'model_ensemble_plot.png' , show_shapes=True, show_layer_names=True)\n",
    "plot_model(model1, to_file= summary_save_path + 'model_1_plot.png', show_shapes=True, show_layer_names=True)\n",
    "plot_model(model2, to_file= summary_save_path + 'model_2_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# model1.summary()\n",
    "# model2.summary()\n",
    "# model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
